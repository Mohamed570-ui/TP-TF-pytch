{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FCGKqTZN7h7",
        "outputId": "072f6dc8-0e54-4732-a9a2-8c43ade76fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model:\n",
            "TinyModel(\n",
            "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
            "  (activation): ReLU()\n",
            "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n",
            "\n",
            "\n",
            "Just one layer:\n",
            "Linear(in_features=200, out_features=10, bias=True)\n",
            "\n",
            "\n",
            "Model params:\n",
            "Parameter containing:\n",
            "tensor([[ 0.0561,  0.0246,  0.0624,  ..., -0.0031, -0.0114,  0.0493],\n",
            "        [-0.0414,  0.0299, -0.0661,  ...,  0.0765,  0.0798, -0.0363],\n",
            "        [-0.0823, -0.0369, -0.0339,  ..., -0.0789,  0.0189,  0.0478],\n",
            "        ...,\n",
            "        [-0.0859, -0.0460,  0.0657,  ...,  0.0142, -0.0779,  0.0139],\n",
            "        [ 0.0481,  0.0052,  0.0249,  ..., -0.0309, -0.0445,  0.0780],\n",
            "        [ 0.0749, -0.0790, -0.0628,  ..., -0.0365,  0.0267, -0.0299]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0856,  0.0489, -0.0135, -0.0646, -0.0709,  0.0477,  0.0537,  0.0158,\n",
            "        -0.0439,  0.0209, -0.0576,  0.0733, -0.0738, -0.0926, -0.0827,  0.0249,\n",
            "        -0.0652, -0.0667,  0.0283,  0.0710,  0.0844, -0.0762, -0.0884,  0.0619,\n",
            "         0.0306,  0.0519, -0.0691,  0.0376, -0.0820, -0.0805, -0.0068, -0.0659,\n",
            "         0.0829, -0.0620,  0.0647, -0.0432, -0.0502,  0.0859,  0.0455,  0.0049,\n",
            "         0.0136, -0.0969,  0.0288,  0.0582, -0.0352,  0.0122, -0.0488, -0.0499,\n",
            "         0.0009,  0.0993,  0.0580,  0.0880,  0.0870, -0.0598,  0.0374, -0.0998,\n",
            "         0.0492,  0.0717, -0.0470, -0.0328,  0.0167,  0.0813, -0.0163, -0.0377,\n",
            "         0.0508,  0.0824,  0.0782, -0.0465,  0.0526,  0.0766, -0.0781, -0.0991,\n",
            "         0.0881, -0.0456,  0.0400, -0.0546,  0.0176,  0.0671,  0.0649,  0.0551,\n",
            "         0.0917,  0.0358, -0.0258, -0.0920,  0.0540, -0.0236, -0.0854,  0.0043,\n",
            "        -0.0466,  0.0335, -0.0468, -0.0865,  0.0074,  0.0685, -0.0197,  0.0531,\n",
            "         0.0562,  0.0297,  0.0427, -0.0617,  0.0814, -0.0642, -0.0321,  0.0407,\n",
            "         0.0266, -0.0444, -0.0075, -0.0168,  0.0835,  0.0368, -0.0126, -0.0704,\n",
            "         0.0848,  0.0732, -0.0463, -0.0663,  0.0223, -0.0399, -0.0331, -0.0137,\n",
            "         0.0109,  0.0272,  0.0203, -0.0190, -0.0361,  0.0454,  0.0373,  0.0036,\n",
            "         0.0369,  0.0623,  0.0488,  0.0116,  0.0579, -0.0787,  0.0691,  0.0040,\n",
            "         0.0461,  0.0993, -0.0092,  0.0868,  0.0547, -0.0382, -0.0956, -0.0714,\n",
            "        -0.0772,  0.0757, -0.0010,  0.0426,  0.0321, -0.0187,  0.0711,  0.0207,\n",
            "         0.0811, -0.0688,  0.0793,  0.0364, -0.0683,  0.0936,  0.0994,  0.0225,\n",
            "         0.0247, -0.0500, -0.0649, -0.0761,  0.0583, -0.0690, -0.0548,  0.0777,\n",
            "        -0.0277,  0.0953,  0.0538,  0.0337, -0.0652,  0.0166, -0.0396, -0.0655,\n",
            "         0.0580, -0.0966,  0.0301,  0.0902,  0.0278,  0.0055, -0.0663, -0.0893,\n",
            "         0.0694,  0.0849, -0.0291, -0.0822, -0.0394, -0.0122,  0.0800,  0.0440,\n",
            "        -0.0557,  0.0495, -0.0405,  0.0913,  0.0253, -0.0120, -0.0468, -0.0212],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0407, -0.0574, -0.0092,  ..., -0.0035,  0.0068,  0.0532],\n",
            "        [-0.0397, -0.0701,  0.0687,  ...,  0.0646, -0.0224,  0.0065],\n",
            "        [ 0.0657, -0.0129,  0.0677,  ...,  0.0517,  0.0433, -0.0071],\n",
            "        ...,\n",
            "        [ 0.0638, -0.0033, -0.0557,  ..., -0.0051,  0.0398, -0.0278],\n",
            "        [ 0.0289,  0.0025,  0.0405,  ..., -0.0247, -0.0671,  0.0138],\n",
            "        [-0.0156, -0.0523,  0.0445,  ..., -0.0209, -0.0442, -0.0065]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0402,  0.0085,  0.0511, -0.0141, -0.0357, -0.0278, -0.0359, -0.0573,\n",
            "         0.0189, -0.0573], requires_grad=True)\n",
            "\n",
            "\n",
            "Layer params:\n",
            "Parameter containing:\n",
            "tensor([[-0.0407, -0.0574, -0.0092,  ..., -0.0035,  0.0068,  0.0532],\n",
            "        [-0.0397, -0.0701,  0.0687,  ...,  0.0646, -0.0224,  0.0065],\n",
            "        [ 0.0657, -0.0129,  0.0677,  ...,  0.0517,  0.0433, -0.0071],\n",
            "        ...,\n",
            "        [ 0.0638, -0.0033, -0.0557,  ..., -0.0051,  0.0398, -0.0278],\n",
            "        [ 0.0289,  0.0025,  0.0405,  ..., -0.0247, -0.0671,  0.0138],\n",
            "        [-0.0156, -0.0523,  0.0445,  ..., -0.0209, -0.0442, -0.0065]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0402,  0.0085,  0.0511, -0.0141, -0.0357, -0.0278, -0.0359, -0.0573,\n",
            "         0.0189, -0.0573], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "class TinyModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(TinyModel, self).__init__()\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(100, 200)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.linear2 = torch.nn.Linear(200, 10)\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "tinymodel = TinyModel()\n",
        "\n",
        "print('The model:')\n",
        "print(tinymodel)\n",
        "\n",
        "print('\\n\\nJust one layer:')\n",
        "print(tinymodel.linear2)\n",
        "\n",
        "print('\\n\\nModel params:')\n",
        "for param in tinymodel.parameters():\n",
        "    print(param)\n",
        "\n",
        "print('\\n\\nLayer params:')\n",
        "for param in tinymodel.linear2.parameters():\n",
        "    print(param)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lin = torch.nn.Linear(3, 2)\n",
        "x = torch.rand(1, 3)\n",
        "print('Input:')\n",
        "print(x)\n",
        "\n",
        "print('\\n\\nWeight and Bias parameters:')\n",
        "for param in lin.parameters():\n",
        "    print(param)\n",
        "\n",
        "y = lin(x)\n",
        "print('\\n\\nOutput:')\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxGBk-aUPYfI",
        "outputId": "ba939a63-b3c3-402e-840c-f6872d522963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            "tensor([[0.0382, 0.8962, 0.8986]])\n",
            "\n",
            "\n",
            "Weight and Bias parameters:\n",
            "Parameter containing:\n",
            "tensor([[-0.4875, -0.2863,  0.1644],\n",
            "        [-0.2794,  0.3093, -0.0810]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.2624, 0.0766], requires_grad=True)\n",
            "\n",
            "\n",
            "Output:\n",
            "tensor([[0.1348, 0.2703]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.functional as F\n",
        "\n",
        "\n",
        "class LeNet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = torch.nn.Linear(120, 84)\n",
        "        self.fc3 = torch.nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "metadata": {
        "id": "wrCEMqtKPe0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMTagger(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "metadata": {
        "id": "Q60CefSaPpUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 6, 6)\n",
        "print(my_tensor)\n",
        "\n",
        "maxpool_layer = torch.nn.MaxPool2d(3)\n",
        "print(maxpool_layer(my_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qul3Bwc7PvEX",
        "outputId": "c78ac24d-d31d-487a-de83-dd65bccc121c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.6476, 0.3397, 0.1132, 0.6026, 0.2618, 0.3625],\n",
            "         [0.0430, 0.2864, 0.4704, 0.3619, 0.8202, 0.3691],\n",
            "         [0.5988, 0.6658, 0.5893, 0.5515, 0.4692, 0.1219],\n",
            "         [0.7008, 0.7103, 0.2590, 0.1653, 0.6981, 0.1959],\n",
            "         [0.4840, 0.0456, 0.2508, 0.8532, 0.5805, 0.8327],\n",
            "         [0.2078, 0.6420, 0.3721, 0.1473, 0.3389, 0.8070]]])\n",
            "tensor([[[0.6658, 0.8202],\n",
            "         [0.7103, 0.8532]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
        "print(my_tensor)\n",
        "\n",
        "print(my_tensor.mean())\n",
        "\n",
        "norm_layer = torch.nn.BatchNorm1d(4)\n",
        "normed_tensor = norm_layer(my_tensor)\n",
        "print(normed_tensor)\n",
        "\n",
        "print(normed_tensor.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiDRFFTNP24D",
        "outputId": "adc78a35-526f-47b9-d4d4-e929c59c94e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 5.7684, 18.9557, 10.5500, 23.3625],\n",
            "         [14.1807,  5.1023, 15.2959, 13.1531],\n",
            "         [ 6.1406, 19.8278,  5.3774, 17.0029],\n",
            "         [15.8121, 14.4119, 10.6463, 20.5659]]])\n",
            "tensor(13.5096)\n",
            "tensor([[[-1.2895,  0.6232, -0.5960,  1.2624],\n",
            "         [ 0.5597, -1.7009,  0.8374,  0.3038],\n",
            "         [-0.9274,  1.2072, -1.0464,  0.7666],\n",
            "         [ 0.1276, -0.2668, -1.3274,  1.4665]]],\n",
            "       grad_fn=<NativeBatchNormBackward0>)\n",
            "tensor(-1.4901e-08, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 4, 4)\n",
        "\n",
        "dropout = torch.nn.Dropout(p=0.4)\n",
        "print(dropout(my_tensor))\n",
        "print(dropout(my_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msHMFrQ-P9Ya",
        "outputId": "49f6d1ae-bed9-4d51-92ad-b3d3d8105212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0000, 1.4278, 0.7384, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.5488],\n",
            "         [0.6868, 1.3794, 0.0000, 1.0119],\n",
            "         [0.6353, 0.0000, 0.0000, 0.4164]]])\n",
            "tensor([[[1.3680, 1.4278, 0.0000, 0.0000],\n",
            "         [0.6438, 0.0000, 0.7920, 0.0000],\n",
            "         [0.6868, 1.3794, 0.8986, 0.0000],\n",
            "         [0.6353, 0.9509, 0.0000, 0.0000]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-DaXsHGKQE1m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}